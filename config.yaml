llm:
  type: "api" # "local"
  model: "google/flan-t5-xxl"
chunking:
  chunk_size: 1000
  chunk_overlap: 100
search: 
  search_strategy: hybrid # dense, hybrid
  alpha: 0.5 # 1 pure vector search, 0 pure keyword search
k_top_chunks: 3
rerank: False
memory:
  window: 5