llm:
  type: "local" # "api" "local"
  model: "Open-Orca/oo-phi-1_5" # "google/flan-t5-xxl" "lmsys/vicuna-7b-v1.5" "Open-Orca/oo-phi-1_5"
chunking:
  chunk_size: 1000
  chunk_overlap: 100
search: 
  search_strategy: hybrid # dense, hybrid
  alpha: 0.6 # 1 pure vector search, 0 pure keyword search
k_top_chunks: 3
rerank: False # to be implemented
memory:
  window: 5